# redis实战之高并发

在redis 存储的所有数据中, 有一部分是被频繁访问的. 有两种情况可能会导致热点问题的产生, 一种是用户集中访问的数据, 例如抢购的商品, 明星结婚或者明星出轨的微博. 还有一种问题是在数据进行分片的情况下, 负载不均衡, 超过了单个服务器的承受能力. 热点数据可能引起缓存服务的不可用, 最终造成压力堆积到数据库. 

处于存储和流量优化的角度, 我们必须要找到这些热点数据. 



## 1. 热点数据的发现

除了自动的缓存淘汰机制之外，怎么找出那些访问频率最高的key呢?或者说, 我们可以在哪里记录key被访问的情况呢? 

### 1.1 客户端

第一个当然是在客户端了, 比如我们可以不可以在所有调用了`get` 、`set` 方法的地方, 加上`key` 的计数. 但是这样的话, 每一个地方都需要修改， 重复的代码也多。如果我们用的是`jedis`的客户端, 我们可以在`jedis`的`connection`类的`sendCommand()` 里面, 用一个`HashMap` 进行key 的计数. 

但是这种方式有几个问题： 

1. 不知道要存多少个key, 可能会发生内存泄漏的问题
2. 会对客户端的代码造成入侵
3. 只能统计当前客户端的热点key



### 1.2 代理层

第二种方式就是在代理层实现,比如`TwemProxy`  或者`Codis`,但是不是所有的项目都是用了代理的架构



### 1.3 服务端

第三种就是在服务端统计, redis有一个`monitor` 的命令, 可以监控到所有redis 执行的命令. 

```java
    public static void main(String[] args) {
        Jedis jedis = JedisUtil.getJedisUtil().getJedis();
        jedis.monitor(new JedisMonitor() {
            @Override
            public void onCommand(String command) {
                System.out.println("#monitor: " + command);
            }
        });
    }

```

`Facebook` 的开源项目  [redis-faina](https://github.com/facebookarchive/redis-faina.git)  就是基于这个原理实现的, 它是一个python 脚本,可以分析`monitor` 的数据

```bash
redis-cli -p 6379 monitor | head -n 100000 | ./redis-faina.py

```



这种方法也有两个问题, 

1. `monitor` 命令在高并发的场景下, 会影响性能, 所以不适合长时间使用. 
2. 只能统计一个redis 节点的热点key



###  1.4 机器层面

还有一种方法就是机器层面的, 通过TCP协议进行抓包,也有一些开源的方案, 比如`ELK`的`packetbeat`插件

当我们发现了热点key之后, 我们来看下热点数据在高并发的场景下可能会出现哪些问题呢? 以及怎么去解决? 



##  2. 缓存雪崩

###  1. 什么是缓存雪崩

缓存雪崩就是redis 的大量热点数据同时过期(失效),因为设置了相同的过期时间, 刚好这个时候redis请求的并发量又很大, 就会导致所有的请求落到数据库. 

### 2. 缓存雪崩的解决方案

1. 加互斥锁或者使用队列, 针对同一个key只允许一个线程到数据库查询
2. 缓存定时预更新,避免同时失效. 
3. 通过加随机数, 使key 在不同的时间过期. 
4. 缓存永不过期. 



## 3. 缓存穿透

###  3.1 缓存穿透何时发生? 

当数据在数据库和redis 里面都不存在, 可能是一次条件错误的查询, 在这种情况下, 因为数据库值是不存在的, 所以肯定不会写入到redis, 那么下一次查询相同的key的时候, 肯定还会到数据库查询一次. 那么这种循环查询数据库中不存在的值, 并且每次都是使用的相同的key 的情况下, 我们有没有办法避免应用直接到数据库查询呢? 

- 缓存空数据
- 缓存特殊字符串

我们可以在数据库缓存一个空字符串,或者缓存一个特殊的字符串, 那么在应用里面拿到这个特殊的字符串的时候, 就知道数据库没有值了, 也没有必要到数据库中查询了. 

这个是应用重复查询同一个存在的值的情况, 如果应用每一次查询的不存在的值是不一样的呢? 即使你每次都缓存特殊字符串也没用, 因为它的值不一样, 比如我们的用户系统登录的场景, 如果是恶意的请求, 它每次都生成了一个符合ID规则的账号, 但是这个账号在我们的数据库是不存在的, 那redis 就完全失去了作用. 

这种因为每次查询的值都不存在导致的redis失效的情况, 我们就把它叫做缓存穿透. 这个问题我们应该怎么去解决呢? 



###  3.2  经典面试题

其实它也是一个通用的问题, 关键在于我们怎么知道请求的key 在我们的数据库是否存在, 如果数据量特别大的情况, 我们怎么去快速判断呢? 

这也是一个非常经典的面试题: 

> 如何在海量元素中(例如10亿无序、不定长、不重复)快速判断一个元素是否存在? 

如果是缓存穿透的这个问题, 我们要避免到数据库查询不存的数据, 肯定要把这10亿放到别的地方. 这些数据在redis 里面也是没有的, 为了加快检索速度, 我们要把数据放到内存里面来判断, 问题来了: 

如果我们直接把这些元素的值放到基本的数据结构(`List`、`Map`，`Tree`)里面, 比如一个元素1字节的字段, 10亿的数据大概需要900G的内存空间, 这个对于普通的服务器来说是承受不了的. 

所以, 我们存储这几十亿个元素,不能直接存值, 我们应该找到一种最简单的最节省空间的数据结构, 用来标记这个元素没有出现. 

这个东西我们就把它叫做位图, 它是一个有序的数组, 只有两个值, 0和1, 0代表不存在, 1代表存在. 

![image-20200403141523714](http://files.luyanan.com//img/20200403141525.png)

那我们怎么用这个数组里面的有序的位置来标记这10亿个元素是否存在? 我们是不是必须要有一个映射的方法, 把元素映射到一个下标位置上? 

对于这个映射方法, 我们有几个基本的要求: 

1. 因为我们的值长度是不固定的, 我希望不同长度的输入, 可以得到固定长度的输出. 
2. 转换成下标的时候, 我希望它在我的这个有序数组里面是分布均匀的, 不然的话全部都挤到一对了, 我也没法判断到底哪个元素存了? 哪个元素没存?

这个是哈希函数, 比如`MD5`、`SHA-1` 等等这些都是常见的哈希算法

![image-20200403143324368](http://files.luyanan.com//img/20200403143325.png)



比如, 这6个元素, 我们经过哈希函数和位运算, 得到了相应的下标. 

###  3.3 哈希碰撞

这个时候, `Tom`和`Mic` 经过计算得到的哈希值是一样的, 那么再经过位运算得到的下标肯定是一样的, 我们把这种情况叫做哈希冲突或者哈希碰撞. 

如果发生了哈希碰撞, 这个时候对于我们的容器存值肯定是有影响的, 我们可以用过哪些方式去降低哈希碰撞的概率呢? 

第一种是扩大位数组的长度或者说位图容量, 因为我们的函数是分布均匀的, 所以,位图容量越大, 在同一个位置发生哈希碰撞的概率就越小. 

是不是位图容量越大就越好呢? 不管存多少个元素, 都创建一个几万亿大小的位图, 可以吗?当然不可以,因为越大的位图容量, 意味着越多的内存消耗, 所以我们要创建一个合适大小的位图容量. 

除了扩大位图容量, 我们还有什么降低哈希碰撞概率的方法呢? 

如果两个元素经过一次哈希计算, 得到的相同下标的概率比较高， 我可以不可以计算多次呢? 原来我只用一个哈希函数, 现在我对于每一个要存储的都用多个哈希函数去计算, 这样每次计算出来的下标都相同的概率就小得多了. 

同样的,我们能不能引入很多歌哈希函数呢? 比如都计算100次, 都可以吗? 当然也会有问题, 第一个就是他会填满位图的更多的空间， 第二个是计算是需要消耗时间的. 

所以总的来说, 我们既要节省空间， 又要很高的计算概率, 就必须在位图容量和函数个数之间找到一个最佳的平衡. 

比如;我们存放100万个元素, 到底需要多大的位图容量, 需要多少个哈希函数呢?



### 3.4 布隆过滤器原理

当然, 这个事情早就有人研究过了, 在1970年的时候, 有一个叫做布隆的前辈对于判断海量元素中元素是否存在的问题进行了研究, 也就是到底需要多大的位图容量和多少个哈希函数, 它发表了一篇论文, 提出的这个容器就叫做布隆过滤器. 

我们来看一下布隆过滤器的工作原理 

首先, 布隆过滤器的本质就是我们刚才分析的, 一个位数组, 和若干个哈希函数. 

![image-20200403144647614](http://files.luyanan.com//img/20200403144648.png)

集合里面有3个元素, 要把它存到布隆过滤器里面去, 应该怎么做呢? 首先是a元素, 这里我们用3次计算, b、c元素也是一样. 

元素都存进去以后, 现在我要来判断一个元素在这个容器中是否存在, 就要使用同样的三个函数进行计算. 

比如d元素, 我用第一个函数f1 计算, 发现这个位置上是1, 没问题, 第二个位置也是1, 第三个位置上也是1. 

如果经过三次计算得到的下标位置值都是1, 这种情况下, 能不能确定d元素一定在这个容器里面呢? 实际上是不能的. 比如这张图里面, 这三个位置分别是把a、b、c 存进去的时候置成1， 所以即使d 元素之前没有存进去, 也会得到三个1, 判断返回true

所以 这个是布隆过滤器的一个很重要的特性, 因为哈希碰撞是不可避免的, 所以它会存在一定的误判率. 这种把本来不存在布隆过滤器中的元素误判为存在的情况, 我们把它叫做 假阳性(`False Positive Probability，FPP`)

我们再来看另一个元素, 我们要判断它在容器中是否存在， 一样的要用这三个函数去计算, 第一个位置是1, 第二个位置是1, 第三个位置是0 

e元素是不是一定不在这个容器里面呢? 可以确定一定不存在,如果说当时已经把e元素存到布隆过滤器里面去了, 那么这三个位置肯定都是1, 不可能会出现0

总结: 布隆过滤器的特点： 

从容器的角度来说：

1. 如果布隆过滤器判断元素在集合中存在, 不一定存在. 
2. 如果布隆过滤器判断不存在, 则一定不存在. 



从元素的角度来说：

3. 如果元素实际存在, 布隆过滤器一定判断存在
4. 如果元素实际不存在,布隆过滤器可能判断存在

利用第二个特性, 我们是不是就可以解决持续从数据库查询不存在的值的问题呢? 



###  3.5 Guava的实现

谷歌的`Guava` 里面就提供了一个现成的布隆过滤器

```xml
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>21.0</version>
</dependency>
```



创建布隆过滤器

```java
BloomFilter<String> bf = BloomFilter.create(
Funnels.stringFunnel(Charsets.UTF_8), insertions);
```



布隆过滤器提供的存放元素的方法是`put()`

布隆过滤器提供的判断元素是否存在的方法是`mightContain()`

```java
if (bf.mightContain(data)) {
  if (sets.contains(data)) {
    // 判断存在实际存在的时候，命中
    right++;
  continue;
}
  // 判断存在却不存在的时候，错误
  wrong++;
}
```



布隆过滤器把误判率默认设置为0.03, 也可以在创建的时候指定

```java
public static <T> BloomFilter<T> create(Funnel<? super T> funnel, long expectedInsertions) {
return create(funnel, expectedInsertions, 0.03D);
}
```



位图的容量是基于元素个数和误判率计算出来的. 

```java
long numBits = optimalNumOfBits(expectedInsertions, fpp);
```



根据位数组的大小, 我们进一步计算哈希函数的个数

```java
int numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits);
```



存储100万个元素, 只占用了0.87M的内存, 生成了5个哈希函数. 

https://hur.st/bloomfilter/?n=1000000&p=0.03&m=&k=



### 3.6 布隆过滤器在项目中的使用

布隆过滤器的工作位置: 

![image-20200403152114168](http://files.luyanan.com//img/20200403152115.png)



因为要判断数据库的值是否存在, 所以第一步是加载数据库所有的数据, 在去redis 查询之前, 先用布隆过滤器查询, 如果bf 说没有, 那数据库也没有, 也就不同去查了. 如果bf说有, 才走之前的路程. 



###  3.7  布隆过滤器的其他应用场景

布隆过滤器解决的问题是什么呢? 如何在海量的元素中快速判断一个元素是否存在, 所以除了解决缓存穿透的问题之外， 还有很多其他的用途. 

比如爬数据的爬虫, 爬过的url 我们不需要进行重复的爬, 那么在几十亿的url里面， 怎么判断一个url 是否已经爬过呢? 

还有我们的邮箱服务器, 发送垃圾邮件的账号我们把它叫做`spamer`,  在这么多的邮箱账号里面, 怎么判断一个账号是不是`spamer` 等等一些场景, 我们都可以用到布隆过滤器. 

