# 分库分表的类型和特点

从维度来说可以分为两种: 一种是垂直, 一种是水平

**垂直切分**: 基于表和字段划分, 表结构不同, 我们有单表的分表， 也有多库的分表. 

**水平切分**: 基于数据切分, 表结构相同, 数据不同, 也有同库的水平切分和多库的切分 

![image-20200404134155501](http://files.luyanan.com//img/20200404134317.png)



## 1. 垂直切分

垂直分表分为两种, 一种是单库的, 一种是多库的. 

### 1.1 单库垂直分表

单库分表, 比如: 商户信息表拆分成基本信息表、联系方式表、结算信息表、附件表. 



###  1.2 多库垂直分表

多库垂直分表就是把原来存储在一个表中不同的表, 拆分在不同的数据库中. 

比如: 消费金融核心数据库, 有很多客户相关的表, 这些客户的表,全部单独存放在客户的数据库中。 

当我们对原来的一张表做了分库的处理, 如果某些业务系统的数据还是一个非常快的增长速度, 比如还款系统的还款历史表, 数据量达到了几十个亿, 这个时候硬件限制导致的问题还是会出现. 所以从这个角度来说垂直拆分并没有从根本上解决单库单表数据量过大的问题. 在这个时候, 我们还需要对我们的数据做一个水平的拆分. 



## 2. 水平拆分

当我们的客户表的数量已经达到数千万甚至上亿的时候, 单表的存储容量和查询效率还是会出现问题, 我们需要进一步对单张表进行水平拆分. 水平拆分的每个数据库的表结构都是一样的, 只是存储的数据不同, 比如每个库存储1000万的数据. 

水平拆分也可以分为两种, 一种是单库的， 一种是多库的. 



### 2.1 单库水平分表

银行的交易流水表, 所有进出的交易记录都需要登记这种表, 因为绝大部分的时候客户都是查询当天的交易和一个月之内的交易数据, 所以我们根据使用频率将这张表拆分成三张表. 

当天表: 存储当天的数据

当月表: 在夜间运行一个定时任务 , 前一天的数据, 全部迁移到当月表。 用到是`insert into insert `,然后`delete`

历史表: 同样是通过定时任务, 把登记时间超过30天的数据,迁移到`history` 历史表(历史表的数据非常大, 我们按照月度, 每个月建立分区)

但是注意, 跟分区一样, 这种方式虽然可以一定程序上解决单表查询性能的问题，但是并不能解决单机存储瓶颈的问题. 



###  2.2 多库水平分表

另一种是多库的水平分表, 比如客户表,我们可以拆分到多个库存储， 表结构是完全一样的. 

一般我们说的分库分表都是跨库的分表. 

既然分库分表能够帮助我们解决性能的问题, 那我们是不是马上就动手去做呢? 甚至在项目设计的时候就先给他分几个库呢? 先来冷静一下，我们来看一下分库分表会带来哪些问题, 也就是我们前面说的分库分表之后带来的复杂性. 



## 3. 分库分表带来的问题

###  3.1 跨库关联问题

比如在查询合同信息的时候要关联客户数据, 由于是合同数据和客户数据在不同的数据库, 那么我们肯定不能直接使用`join` 的这种方式来做关联查询. 

我们有几种主要的解决方案:

1. 字段冗余

    比如我们在查询合同库的合同表的时候要关联客户库的客户表, 我们可以直接把一些经常关联查询的客户字段放到合同表, 通过这种方式来避免跨库关联查询的问题 

2. 数据同步

     比如商户系统要查询产品系统的产品表, 我们干脆在商户系统里面创建一张产品部, 通过`ELK` 或者其他定时任务的方式定时同步产品数据. 

3. 全局表(广播表)

    比如行名行号等被很多业务系统用到, 如果我们放在核心系统 , 每个系统都要去关联查询, 这个时候我们可以在所有的数据库中都存储相同的基础数据. 

4. `ER`表(绑定表)

    我们有些表的数据是存在逻辑的主外键关系的, 比如订单表`order_info`, 存的是汇总的商品数, 商品金额, 订单明细表`order_detail`, 是每个商品的价格, 个数等. 或者叫做从属关系, 父表和子表的关系. 他们之间会经常有关联查询的操作, 如果父表的数据和子表的数据分别存储在不同的数据库, 跨库关联查询也比较麻烦, 所以我们能不能把父表的数据和从属于父表的数据落到同一个节点上呢?
    
     比如`order_id=1001`的数据在`node1`, 他所有的明细数据也放到`node1`, `order_id=1002`的数据在`node2`, 他所有的明细数据都放在`node2`, 这样的关联查询的时候依然是在一个数据库. 
    
    上面的思路都是通过合理的数据分布避免跨距关联查询, 实际上在我们的业务中, 也是尽量不要使用跨库关联查询, 如果出现了这种情况, 就要分析一下业务或者数据拆分是不是合理, 如果还是出现了需要跨库关联的情况, 那我们就只能用最后一种办法了. 
    
5. 系统层组装. 

     在不同的数据库节点把符合条件的数据查询出来, 然后重新组装, 返回给客户端. 

###  3.2 分布式事务

比如在一个贷款的流程里面, 合同系统登记了数据, 放款系统也必须生成放款记录, 如果两个不同的动作不是同时成功或者同时失败, 就会出现数据不一致的问题. 如果在一个数据库里面,我们可以用本地事务来控制, 但是在不同的数据库里面就不行了，所以分布式环境里面的事务, 我们也需要一些方案来解决. 

这里需要说一下分布式系统的基本是`CAP` 理论. 

1. `C` (一致性）`Consistency`: 对某个指定的客户端来说, 读操作能返回最新的写操作,对于数据分布在不同节点上的数据来说,如果某个节点更新了数据, 那么在其他节点如果都读取到了这个最新的数据,. 那么就称为强一致, 如果有某个节点没有读取到, 那么就是分布式不一致. 

2. `A`（可用心）`Availability`: 非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应), 可用性的两个关键一个是合理的时间, 一个是合理的响应. 

    合理的时间指的是请求不能被无限的阻塞,应该在合理的时间内给予返回. 合理的响应指的是系统应该明确返回结果并且结果是正确的. 

3. `P`(分区容错性)`Partition tolerance` : 当出现网络分区后, 系统能够继续工作, 打个比方, 这里集群有多台机器, 有台机器的网路出现了问题, 但是这个集群然然可以正常的工作. 

`CAP`  三者是不能共有的, 只能同时满足其中的两点, 基于`AP`, 我们就有了`BASE` 理论.

    -   **基本可用`(Basically Available)`:** 分布式系统在出现故障时,允许损失部分可用功能， 保证核心功能可用. 
    -   **软状态(`(Soft state)`):** 允许系统中存在中间状态,这个状态不影响系统可用性, 这里指的是`CAP` 中的不一致。
    -   **最终一致(`Eventually consistent`):** 最终一致性是指经过一段时间后, 所有的节点数据都会达到一致. 

分布式事务有几种场景的解决方案: 

1. 全局事务(比如`XA` 两阶段提交:应用、事务管理器(`TM`)、资源管理器(DB)), 例如`Atomikos`

2. 基于可靠消息服务的分布式事务

    ![image-20200404152822604](http://files.luyanan.com//img/20200404152824.png)	

3. 柔性事务`TTC` `（Try-Confirm-Cancel）tcc-transaction` ![image-20200404153007862](http://files.luyanan.com//img/20200404153009.png)

4. 最大努力通知, 通过消息中间件向其他消息发送消息(重复投递+定时校对)



### 3.3  排序、翻页、函数计算问题

跨节点多库查询进行查询, 会出现`limit`分页, `order by` 排序的问题, 比如有两个节点， 节点上存的是奇数id = 1,3,5,7,9.....; 节点2上存的是id = 2,4,6,8,10...

执行`select * from user_info order by id limit 0,10`

需要在两个节点上各取出10条, 然后合并数据, 重新排序. 

`max、min、sum、count` 之类的函数在进行计算的时候, 也需要先在每个分片上执行相应的函数, 然后将各个分片的结果集进行汇总和再次计算, 最终将结果返回. 



###  3.4 全局主键避重问题

`MYSQL` 的数据库里面字段有一个自增的属性, `Oracle` 也有`Sequence` 序列. 如果是一个数据库, 那么可以保证ID是不重复的, 但是水平分表后, 每个表都按照自己的规律自增, 肯定会出现ID重复的问题, 这个时候我们就不能用本地自增的方式. 

我们有几种常见的解决方案: 

####  1. `UUID` （`Universally Unique Identifier` 通用唯一识别码）

 `UUID`  标准形式包含32个16 进制数字, 分为5段, 形式为`8-4-4-4-12` 的36个字符, 例如:`c4e7956c-03e7-472c-8909-d733803e79a9`



| `Name`                                      | `Length (Bytes)` | `Length (Hex Digits)` | `Contents`                                                   |
| ------------------------------------------- | ---------------- | --------------------- | ------------------------------------------------------------ |
| `time_low`                                  | 4                | 8                     | `integer giving the low 32 bits of the time`                 |
| `time_mid`                                  | 2                | 4                     | `integer giving the middle 16 bits of the time`              |
| `time_hi_and_version`                       | 2                | 4                     | `4-bit "version" in the most significant bits, followed by the high 12 bits of the time` |
| `clock_seq_hi_and_res`<br />`clock_seq_low` | 2                | 4                     | `1-3 bit "variant" in the most significant bits, followed by the 13-15 bit clock sequence` |
| `node`                                      | 6                | 12                    | `the 48-bit node id`                                         |



`xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx`

M 表示UUID的版本,目前只有5个版本,即指挥出现1,2,3,4,5 , 数字N 的一至三个最高有效位标识UUID 变体, 目前指挥出现8,9,a,b  四种情况。

1. 基于时间和MAC地址的UUID
2. 基于第一版却更加安全的`DCE UUID`
3. 基于`md5` 散列算法的`uuid`
4. 基于随机数的UUID, 用的最多, JDK里面是4
5. 基于`SHA1`散列算法的`UUID`

`UUID` 是主键的最简单的方案, 本地生成, 性能高, 没有网络的消耗. 但是缺点也很明显, 由于`uuid` 非常长,会占用大量的存储空间;另外, 作为主键建立索引和基于索引进行查询时都会存在性能问题, 在`InnoDB` 中, `UUID`的无序性会引起数据位置频繁变动, 导致分页. 



####  2. 基于数据库

把序号维护在数据库的一张表中, 这张表记录了全局主键的类型、位数、起始值、当前值.当其他应用需要获取全局ID时, 先`for update`锁行, 取到值+1后并且更新后返回, 并发性比较差. 



### 3. redis

基于redis 的`int` 自增的特性, 使用批量的方式降低数据库的写压力, 每次获取一段区间的ID号段, 用完之后再去数据库获取, 可以大大减轻数据库的压力. 



#### 4. 雪花算法`Snowflake`(64bit)

![image-20200404164513365](http://files.luyanan.com//img/20200404164514.png)

核心思想: 

1. 使用41bit作为毫秒数, 可以使用69年
2. 10bit作为机器的id(5bit是数据中心, 5bit的机器id), 支持1024个节点
3. 12bit 作为毫秒内的流水号(在每个节点上每毫秒可以产生4096个ID)
4. 最后还有一个符号位, 永远是0





优点: 毫秒数在高位, 生成的ID 整体上按照时间趋势递增, 不依赖第三方系统, 稳定性和效率较高, 理论上QPS 约为409.6w/s(1000*2^12), 并且分布式环境中不会产生ID 碰撞,  可根据自身业务灵活分配bit位. 

不足在于:强依赖机器的时钟, 如果时钟回拨, 则可能导致生成ID 重复. 

但我们对数据做了切分， 分布在不同的节点上存储的时候, 是不是就意味着产生多个数据源呢? 既然有了多个数据源, 那么我们的项目中就要配置多个数据源了. 

现在问题来了, 我们在执行一条sql 语句的时候, 比如插入, 他应该是在哪个数据库节点上执行呢? 又比如查询, 如果只是在其中的一个节点上面, 我怎么知道在哪个节点呢? 是不是要在所有的数据库节点上都查询一遍才能拿到结果? 

那么, 从客户端到服务端， 我们可以在哪些层面解决这些问题呢? 



##  4. 多数据源/读写数据源的解决方案

我们先要分析一下SQL执行经过的流程. 

> DAO——Mapper（ORM）——JDBC——代理——数据库服务



### 4.1 客户端DAO层

第一个就是在我们的客户端代码,比如DAO层, 在我们连接到某一个 数据源之前, 我们先根据配置的分片规则, 判断需要连接到哪些节点, 再建立连接. 

Spring中提供了一个抽象类, `AbstractRoutingDataSource`  可以实现数据源的动态切换. 

 步骤如下: 

1. 在`application`文件中定义多个数据源
2. 创建`@TargetDataSource` 注解, 定义需要切换的数据源
3. 创建`DynamicDataSource` 继承`AbstractRoutingDataSource`
4. 多数据源配置类`DynamicDataSourceConfig`
5. 创建切面类`DataSourceAspect`, 添加对`@TargetDataSource` 注解的类进行拦截设置数据源
6. 在启动类上自动装配数据源配置`@Import({DynamicDataSourceConfig.class})`
7. 在实现类上加上注解, 如`@TargetDataSource(name = DataSourceNames.SECOND)`  调用. 



代码实例： 

`application`

```properties
server.port=8082
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver
# 数据源1
spring.datasource.druid.first.url=jdbc:mysql://localhost:3306/ds0?allowMultiQueries=true&useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=GMT%2B8
spring.datasource.druid.first.username=root
spring.datasource.druid.first.password=123456
# 数据源2
spring.datasource.druid.second.url=jdbc:mysql://localhost:3306/ds1?allowMultiQueries=true&useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=GMT%2B8
spring.datasource.druid.second.username=root
spring.datasource.druid.second.password=123456


```

`TargetDataSource` 注解

```java
/**
 * 多数据源注解
 * <p/>
 * 指定要使用的数据源
 *
 */
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface TargetDataSource {

    String name() default "";

}

```

`DynamicDataSource`

```java

/**
 * 扩展 Spring 的 AbstractRoutingDataSource 抽象类，重写 determineCurrentLookupKey 方法
 * 动态数据源
 * determineCurrentLookupKey() 方法决定使用哪个数据源
 *
 */
public class DynamicDataSource extends AbstractRoutingDataSource {

    private static final ThreadLocal<String> CONTEXT_HOLDER = new ThreadLocal<>();

    /**
     * 决定使用哪个数据源之前需要把多个数据源的信息以及默认数据源信息配置好
     *
     * @param defaultTargetDataSource 默认数据源
     * @param targetDataSources       目标数据源
     */
    public DynamicDataSource(DataSource defaultTargetDataSource, Map<Object, Object> targetDataSources) {
        super.setDefaultTargetDataSource(defaultTargetDataSource);
        super.setTargetDataSources(targetDataSources);
        super.afterPropertiesSet();
    }

    @Override
    protected Object determineCurrentLookupKey() {
        return getDataSource();
    }

    public static void setDataSource(String dataSource) {
        CONTEXT_HOLDER.set(dataSource);
    }

    public static String getDataSource() {
        return CONTEXT_HOLDER.get();
    }

    public static void clearDataSource() {
        CONTEXT_HOLDER.remove();
    }

}

```



`DynamicDataSourceConfig`

```java
**
 * 配置多数据源
 */
@Configuration
public class DynamicDataSourceConfig {

    @Bean
    @ConfigurationProperties("spring.datasource.druid.first")
    public DataSource firstDataSource(){

        return DruidDataSourceBuilder.create().build();
    }

    @Bean
    @ConfigurationProperties("spring.datasource.druid.second")
    public DataSource secondDataSource(){

        return DruidDataSourceBuilder.create().build();
    }

    @Bean
    @Primary
    public DynamicDataSource dataSource(DataSource firstDataSource, DataSource secondDataSource) {
        Map<Object, Object> targetDataSources = new HashMap<>(5);
        targetDataSources.put(DataSourceNames.FIRST, firstDataSource);
        targetDataSources.put(DataSourceNames.SECOND, secondDataSource);
        return new DynamicDataSource(firstDataSource, targetDataSources);
    }

}

```

`DataSourceAspect`

```java
/**
 * 多数据源，切面处理类
 */
@Slf4j
@Aspect
@Component
public class DataSourceAspect implements Ordered {

    @Pointcut("@annotation(com.dynamic.datasource.TargetDataSource)")
    public void dataSourcePointCut() {

    }

    @Around("dataSourcePointCut()")
    public Object around(ProceedingJoinPoint point) throws Throwable {
        MethodSignature signature = (MethodSignature) point.getSignature();
        Method method = signature.getMethod();

        TargetDataSource ds = method.getAnnotation(TargetDataSource.class);
        if (ds == null) {
            DynamicDataSource.setDataSource(DataSourceNames.FIRST);
            log.debug("set datasource is " + DataSourceNames.FIRST);
        } else {
            DynamicDataSource.setDataSource(ds.name());
            log.debug("set datasource is " + ds.name());
        }

        try {
            return point.proceed();
        } finally {
            DynamicDataSource.clearDataSource();
            log.debug("clean datasource");
        }
    }

    @Override
    public int getOrder() {
        return 1;
    }
}

```

启动类

```java
@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})
@Import({DynamicDataSourceConfig.class})
public class DatabaseDynamicApplication {

    public static void main(String[] args) {
        SpringApplication.run(DatabaseDynamicApplication.class, args);
    }

}

```



调用

```java
/**
 * <p>
 * 系统用户 服务实现类
 * </p>
 *
 */
@Service
public class SysUserServiceImpl extends ServiceImpl<SysUserMapper, SysUser> implements SysUserService {

    @Override
    public SysUser findUserByFirstDb(long id) {
        return this.baseMapper.selectById(id);
    }

    @TargetDataSource(name = DataSourceNames.SECOND)
    @Override
    public SysUser findUserBySecondDb(long id) {

        return this.baseMapper.selectById(id);
    }

}
```



在`DAO`层实现的优势: 不需要依赖ORM框架, 即使替换了`ORM` 框架也不受影响, 实现简单(不需要解析SQL 和路由规则), 可以灵活的定制, 

缺点: 不能复用, 不能跨语言. 



###  4.2 `ORM` 框架层

第二个是在框架层, 比如我们用`Mybatis`连接数据库, 也可以指定数据源, 我们可以基于`Mybatis` 插件的拦截机制(拦截`query`和`update`), 实现数据源的选择. 

例如: https://github.com/colddew/shardbatis

https://docs.jboss.org/hibernate/stable/shards/reference/en/html_single/



### 4.3  驱动层

不管是`Mybatis` 还是`Hobernate` 还是`Spring jdbcTemplate` , 本质上都是对jdbc的封装, 所以第三层就是驱动层. 比如`Sharding-JDBC`,就是对JDBC 的对象进行了封装. JDBC 的核心对象: 

`DataSource`: 数据源

`Connection`: 数据库连接

`Statement`: 语句对象

`ResultSet`: 结果集. 



那我们只要对这几个对象进行拦截或者代理, 就可以实现分片的操作. 



###  3.4 代理层

前三种都是在客户端实现的, 也就是说不同的项目都要做同样的改动, 不同的编程语言也有不同的实现. 所以我们能不能把这种选择数据源和实现路由的逻辑提取出来, 做成一个公共的服务给所有的客户端使用呢? 

这个就是第四层, 代理层. 比如`Mycat`、`Sharding-Proxy`,都是属于这一层. 



### 3.5  数据库服务

最后一层就是在数据库服务上实现, 也就是服务层, 某些特定的数据库或者数据库的特定版本可以实现这个功能. 

